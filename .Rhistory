m <- (lm(mpg ~ am + wt + hp, cars))
plot(m  , 1)
plot(m  , 2)
summary(m)
m <- (lm(mpg ~ am + wt
, cars))
summary(m)
m <- (lm(mpg ~ am
, cars))
summary(m)
plot(m  , 1)
m <- (lm(mpg ~ am + wt + hp, cars))
summary(m)
install.packages("leaps")
library(leaps)
b <- regsubsets(mpg ~ ., data = cars)
b
b <- regsubsets(mpg ~ am, data = cars)
b <- regsubsets(mpg ~ ., data = cars)
summary(b)
b <- regsubsets(mpg ~ ., data = cars, nbest = 1)
b <- regsubsets(mpg ~ ., data = cars, nbest = 2)
b <- regsubsets(mpg ~ ., data = cars, nbest = 1, nested = T)
b <- regsubsets(mpg ~ ., data = cars, nbest = 1, nested = F)
b <- regsubsets(mpg ~ ., data = cars, nbest = 2, nested = F)
b <- regsubsets(mpg ~ ., data = cars, nbest = 2, nested = T)
b
summary(b)
plot(b)
b <- regsubsets(mpg ~ ., data = cars)
plot(b)
install.packages(c("callr", "data.table", "DBI", "directlabels", "dplyr", "foreign", "Formula", "GGally", "ggthemes", "htmlTable", "htmlwidgets", "httpuv", "MASS", "miniUI", "modelr", "openxlsx", "packrat", "pillar", "psych", "purrr", "quantreg", "Rcpp", "readxl", "rlang", "shiny", "sourcetools", "stringi", "stringr", "tidyr", "UsingR", "utf8", "wesanderson", "yaml"))
install.packages(c("callr", "data.table", "DBI", "directlabels", "dplyr", "foreign", "Formula", "GGally", "ggthemes", "htmlTable", "htmlwidgets", "httpuv", "MASS", "miniUI", "modelr", "openxlsx", "packrat", "pillar", "psych", "purrr", "quantreg", "Rcpp", "readxl", "rlang", "shiny", "sourcetools", "stringi", "stringr", "tidyr", "UsingR", "utf8", "wesanderson", "yaml"))
install.packages(c("callr", "data.table", "DBI", "directlabels", "dplyr", "foreign", "Formula", "GGally", "ggthemes", "htmlTable", "htmlwidgets", "httpuv", "MASS", "miniUI", "modelr", "openxlsx", "packrat", "pillar", "psych", "purrr", "quantreg", "Rcpp", "readxl", "rlang", "shiny", "sourcetools", "stringi", "stringr", "tidyr", "UsingR", "utf8", "wesanderson", "yaml"))
install.packages(c("shiny"))
install.packages(c("shiny"))
install.packages(c("shiny"))
install.packages(c("caret"))
install.packages(c("caret"))
install.packages(c("broom", "devtools", "dplyr", "ggplot2", "haven", "httpuv", "survival", "tinytex"))
library(caret)
install.packages("hmisc")
install.packages("Hmisc")
?hmisc
library(iris)
data(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
fit <- train(Species ~ ., method = "rpart", data = training)
install.packages("e1071")
fit <- train(Species ~ ., method = "rpart", data = training)
print(fit$finalModel)
plot(fit$finalModel)
plot(fit$finalModel, uniform = TRUE)
text((fit$finalModel, use.n = TRUE, all = TRUE, , cex = .8)
text((fit$finalModel, use.n = TRUE, all = TRUE,  cex = .8)
text(fit$finalModel, use.n = TRUE, all = TRUE,  cex = .8)
install.packages("rattle")
predict(fit, newdata = testing)
fit2 <- train(Species ~ ., data = training, method = "rf", prox = TRUE)
fit2 <- train(Species ~ ., data = training, method = "rf", prox = TRUE)
fit2
dim(training)
fit3 <- train(mpg ~ ., data = mtcars, method = "rf", prox = TRUE)
fit3
predict(fit3, newdata = mtcars)
confusionMatrix(predict(fit3, newdata = mtcars), mtcars$mpg)
confusionMatrix(predict(fit3, newdata = mtcars)$mpg, mtcars$mpg)
mpggg <- predict(fit3, newdata = mtcars)$mpg
mpggg <- predict(fit3, newdata = mtcars)
mpggg
confusionMatrix(mpggg, mtcars$mpg)
confusionMatrix(mpggg, mtcars)
mtcars$mpg
mpggg$mpg
plot(mpggg)
plot(fit3)
plot(fit3$finalModel)
fit3$bestTune
summary(fit3)
fit3$coefnames
residuals(fit3)
(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = Case, p = 0.7, data = segmentationOriginal)
inTrain <- createDataPartition(y = Case, data = segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p=0.7)
train1 <- segmentationOriginal[inTrain, ]
segmentationOriginal[1,1]
segmentationOriginal[1,]
inTrain
train1 <- segmentationOriginal[inTrain, ]
class(segmentationOriginal)
class(inTrain)
train1 <- segmentationOriginal[as.vector(inTrain), ]
inTrain <- c(inTrain)
class(inTrain)
unlist(inTrain)
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
> training <- iris[inTrain, ]
> testing <- iris[-inTrain,]
inTrain <- createDataPartition(y = iris$Species, p = 0.7, list = FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain,]
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7, list = FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain,]
training
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7, list = FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain,]
training
set.seed(125)
fit <- train(Case ~ ., data = training, method = "rpart")
fit$finalModel
predict(fit, newdata = data.frame(FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2))
predict(fit, newdata = data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2))
predict(fit, newdata = data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2, Cell=0))
predict(fit, newdata = data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2, Cell=0, Class=0))
treebagFuncs
tree()
plot(cars)
plot(cars)
plot(cars)
exp(-10.6513+0.0055*1000)/(1+exp(-10.6513+0.0055*1000))
exp(-6 + 0.05*40 + 1*3.5)/(1+exp(-6 + 0.05*40 + 1*3.5))
round(exp(-6 + 0.05*40 + 1*3.5)/(1+exp(-6 + 0.05*40 + 1*3.5)), 2)
h = 80
round(exp(-6 + 0.05*h + 1*3.5)/(1+exp(-6 + 0.05*h + 1*3.5)), 2)
h= 50
round(exp(-6 + 0.05*h + 1*3.5)/(1+exp(-6 + 0.05*h + 1*3.5)), 2)
?rnorm
adv <- readRDS("~/Downloads/adv.rds")
adv
names(adv)
library(caret)
trCtrl <- trainControl(method = "cv", number = 3)
inTrain <- createDataPartition(adv$sales, p = 0.7, list = FALSE)
trainingData <- adv[inTrain,]
testingData <- adv[-inTrain,]
modelLda <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "lda")
modelQda <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "qda")
modelRf <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "rf")
modelRf
modelRpart <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "rpart")
modelRpart
pred <- predict(modelRf, testingData[,-4])
head(pred)
confusionMatrix(pred, testingData$sales)
confusionMatrix(pred, testingData)
confusionMatrix(pred, testingData[,-4])
modelRf
modelRf$finalModel
table(pred)
testingData$sales
pred
class((pred)
)
levels(pred)
names(pred)
unlist(pred)
unlist(pred, recursive = TRUE)
unlist(pred, recursive = TRUE, use.names = TRUE)
pred[[1]]
pred[[12
]]
names(testingData$sales) <- names(pred)
testingData$sales
confusionMatrix(pred, testingData[,-4])
confusionMatrix(pred, testingData$sales)
?predict
u <- union(pred, testingData$sales)
t <- table(factor(pred, u), factor(testingData$sales, u))
t
confusionMatrix(t)
pred
t <- tbl_df(pred)
library(tidyverse)
t <- tbl_df(pred)
t
t$value
t$actual <- testingData$sales
t
confusionMatrix(t$value, t$actual)
confusionMatrix(t)
modelRf$finalModel
modelRf
RMSE(t$value, t$actual)
plot(modelRf)
RMSE(t$value, t$value)
trCtrl <- trainControl(method = "cv", number = 10)
modelRf <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "rf")
modelRf
k3rmse <- RMSE(t$value, t$actual)
k10rmse <- RMSE(tbl_df(predict(modelRf, testingData[,-4])$value, t$actual)
)
k10rmse <- RMSE(tbl_df(predict(modelRf, testingData[,-4]))$value, t$actual)
k10rmse
k3rmse
RMSE(tbl_df(predict(modelRf, testingData[,-4]))$value, t$actual)
modelRf <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "rf", ntree = 1000)
RMSE(tbl_df(predict(modelRf, testingData[,-4]))$value, t$actual)
plot(adv)
View(adv)
modelLm <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "lm")
modelLm
modelLm$finalModel
summary(modelLm$finalModel)
predict(modelRf, newdata = data.frame( TV = 230.1, radio = 37.8, newspaper = 69.2) )
predict(modelLm, newdata = data.frame( TV = 230.1, radio = 37.8, newspaper = 69.2) )
varImp(modelRf)
varImp(modelLm)
?varImp
varImp(modelLm)
varImp(modelRf)
modelRf <- train(sales ~ ., data = trainingData, trControl = trCtrl, method = "rf", ntree = 1000, importance = TRUE)
varImp(modelRf)
featurePlot(fadv)
featurePlot(adv)
featurePlot(adv$sales, adv$TV)
library(GGally
)
ggpairs(adv)
boxplot(adv)
View(modelRf)
boxplot(t$Sales)
boxplot(t)
boxplot(adv)
boxplot(adv$sales)
boxplot(adv$sales, predict(modelRf,t))
boxplot(adv$sales, predict(modelRf,adv))
plot(adv$sales)
summary(adv)
install.packages("tm")
install.packages("RWeka")
install.packages("RWeka")
gc()
?Weka_control
?Weka_control
?NGramTokenizer
library(RWeka)
install.packages("quanteda")
install.packages("gettext")
packageVersion('quanteda')
install.packages("readtext")
update.packages()
update.packages()
install.packages("shiny")
install.packages("devtools")
library(quanteda)
rm(list=ls())
gc()
knitr::opts_chunk$set(echo = TRUE)
setwd("~/GitHub/dscap/")
library(quanteda)
library(readtext)
library(stringr)
library(glue)
library(data.table)
gc()
db <- readRDS("db.rds")
summary(db)
clearInput <- function(input) {
## "Go on a romantic date at the"
out <- stringr::str_to_lower(input)
out <- stringr::str_replace_all(out, "[[:punct:]]", "")
out <- stringr::str_replace_all(out, "[[:cntrl:]]", "")
out <- stringr::str_replace_all(out, "[[:digit:]]", "")
out <- stringr::str_squish(out)
}
doPredict <- function(normInput) {
sent_chunks <- stringr::str_split(normInput, " ", simplify = TRUE)
#
#      [,1] [,2] [,3] [,4]       [,5]   [,6] [,7]
# [1,] "go" "on" "a"  "romantic" "date" "at" "the"
nwords <- ncol(sent_chunks)
max_pred <- 5
if (nwords == 0 )
return("")
if (nwords > max_pred) {
sent_chunks <- matrix(sent_chunks[, ((nwords - max_pred) + 1):nwords], nrow = 1)
nwords <- ncol(sent_chunks)
}
search_str <- c()
chr <- nwords
while(chr > 0) {
idx <- chr:nwords
search_str <- append(search_str, paste0(sent_chunks[, idx], collapse = "_"))
chr <- chr - 1
}
search_str
#"?"
}
t <- clearInput("Go on a romantic date at the")
t
doPredict(t)
head(db$n3)
db$n3[like(feat, "at_the" )]
db$n4[like(feat, "date_at_the" )]
db$n5[like(feat, "romantic_date_at_the" )]
db$n3[like(feat, "at_the" )]
db$n3[like(feat, "in_the" )]
db$n6[like(feat, "a_romantic_date_at_the" )]
db$n6
str <- "you, I'd live and I'd"
s <- clearInput(str)
s
doPredict(s)
db$n6[like(feat, "you_id_live_and_id" )]
db$n5[like(feat, "id_live_and_id" )]
db$n4[like(feat, "live_and_id" )]
db$n4[like(feat, "live_and_i'd" )]
db$n6[like(feat, "you_i'd_live_and_i'd" )]
rm(list=ls())
shiny::runApp('GitHub/dscap/ShinAppDsCapstone')
library(tidyverse)
# https://cloud.google.com/bigquery/public-data/nyc-tlc-trips
# https://bigquery.cloud.google.com/table/nyc-tlc:yellow.trips?tab=schema
rm(list = ls(all = TRUE))
##library(bigrquery)
library(tidyverse)
library(plotly)
# project <- "testds-215409"
# sql <- "SELECT
# substr(cast(pickup_datetime as String), 1, 7) as date
# ,payment_type as type
# ,sum(total_amount) as amount
#
# FROM `nyc-tlc.yellow.trips`
# group by 1, 2"
#df <- query_exec(sql, project = project,
#                 use_legacy_sql = FALSE)
#plot_ly(df, x = ~date, y = ~amount,
#        color = ~type) %>% add_lines()
#saveRDS(df, "df.rds")
setwd("/Users/usr/Desktop/")
t <- readRDS("/Users/usr/Desktop/tbl_df_nyc.rds")
summary(t)
## remove dispute transactions
t$type <- toupper(t$type)
d <- filter(t, type != "DIS")
d <- filter(d, amount > 0)
d <- mutate(d , ptype = case_when(
type == "CRD" | type == "CRE" ~  "CREDIT",
type == "CAS" | type == "CSH" ~  "CASH",
type == "NA " | type == "UNK" ~  "UNKNOWN",
type == "NOC" | type == "NO " ~  "NO CHARGE",
TRUE ~ "OTHER"
))
d <- filter(d , ptype == "CREDIT" | ptype == "CASH")
## remove raw type row
d <- d[, c(1, 3, 4)]
summary(d)
by_date_type <- group_by(d, date, ptype)
by_date_type$amount <- by_date_type$amount / 1000
g <- ggplot(by_date_type, aes(x = date, y = amount, col = ptype))
g + geom_point() + theme(axis.text.x = element_text(angle = 75, hjust = 1))
setwd("/Users/usr/Desktop/")
setwd("~/GitHub/sba-1")
# https://cloud.google.com/bigquery/public-data/nyc-tlc-trips
# https://bigquery.cloud.google.com/table/nyc-tlc:yellow.trips?tab=schema
rm(list = ls(all = TRUE))
##library(bigrquery)
library(tidyverse)
library(plotly)
# project <- "testds-215409"
# sql <- "SELECT
# substr(cast(pickup_datetime as String), 1, 7) as date
# ,payment_type as type
# ,sum(total_amount) as amount
#
# FROM `nyc-tlc.yellow.trips`
# group by 1, 2"
#df <- query_exec(sql, project = project,
#                 use_legacy_sql = FALSE)
#plot_ly(df, x = ~date, y = ~amount,
#        color = ~type) %>% add_lines()
#saveRDS(df, "df.rds")
#setwd("/Users/usr/Desktop/")
setwd("~/GitHub/sba-1")
t <- readRDS("/Users/usr/Desktop/tbl_df_nyc.rds")
summary(t)
## remove dispute transactions
t$type <- toupper(t$type)
d <- filter(t, type != "DIS")
d <- filter(d, amount > 0)
d <- mutate(d , ptype = case_when(
type == "CRD" | type == "CRE" ~  "CREDIT",
type == "CAS" | type == "CSH" ~  "CASH",
type == "NA " | type == "UNK" ~  "UNKNOWN",
type == "NOC" | type == "NO " ~  "NO CHARGE",
TRUE ~ "OTHER"
))
d <- filter(d , ptype == "CREDIT" | ptype == "CASH")
## remove raw type row
d <- d[, c(1, 3, 4)]
summary(d)
by_date_type <- group_by(d, date, ptype)
by_date_type$amount <- by_date_type$amount / 1000
g <- ggplot(by_date_type, aes(x = date, y = amount, col = ptype))
g + geom_point() + theme(axis.text.x = element_text(angle = 75, hjust = 1))
g <- ggplot(by_date_type, aes(x = date, y = amount, col = ptype))
# https://cloud.google.com/bigquery/public-data/nyc-tlc-trips
# https://bigquery.cloud.google.com/table/nyc-tlc:yellow.trips?tab=schema
rm(list = ls(all = TRUE))
##library(bigrquery)
library(tidyverse)
library(plotly)
# project <- "testds-215409"
# sql <- "SELECT
# substr(cast(pickup_datetime as String), 1, 7) as date
# ,payment_type as type
# ,sum(total_amount) as amount
#
# FROM `nyc-tlc.yellow.trips`
# group by 1, 2"
#df <- query_exec(sql, project = project,
#                 use_legacy_sql = FALSE)
#plot_ly(df, x = ~date, y = ~amount,
#        color = ~type) %>% add_lines()
#saveRDS(df, "df.rds")
#setwd("/Users/usr/Desktop/")
setwd("~/GitHub/sba-1")
t <- readRDS("/Users/usr/Desktop/tbl_df_nyc.rds")
summary(t)
## remove dispute transactions
t$type <- toupper(t$type)
d <- filter(t, type != "DIS")
d <- filter(d, amount > 0)
d <- mutate(d , ptype = case_when(
type == "CRD" | type == "CRE" ~  "CREDIT",
type == "CAS" | type == "CSH" ~  "CASH",
type == "NA " | type == "UNK" ~  "UNKNOWN",
type == "NOC" | type == "NO " ~  "NO CHARGE",
TRUE ~ "OTHER"
))
d <- filter(d , ptype == "CREDIT" | ptype == "CASH")
## remove raw type row
d <- d[, c(1, 3, 4)]
summary(d)
by_date_type <- group_by(d, date, ptype)
by_date_type$amount <- by_date_type$amount / 1000
g <- ggplot(by_date_type, aes(x = date, y = amount, col = ptype))
g + geom_point() + theme(axis.text.x = element_text(angle = 75, hjust = 1))
rm(list = ls(all = TRUE))
library(tidyverse)
library(plotly)
install.packages("plotly")
library(tidyverse)
library(plotly)
setwd("~/GitHub/sba-1")
t <- readRDS("/Users/usr/Desktop/tbl_df_nyc.rds")
setwd("~/GitHub/sba-1")
getwd()
t <- readRDS("tbl_df_nyc.rds")
summary(t)
t$type <- toupper(t$type)
d <- filter(t, type != "DIS")
d <- filter(d, amount > 0)
d <- mutate(d , ptype = case_when(
type == "CRD" | type == "CRE" ~  "CREDIT",
type == "CAS" | type == "CSH" ~  "CASH",
type == "NA " | type == "UNK" ~  "UNKNOWN",
type == "NOC" | type == "NO " ~  "NO CHARGE",
TRUE ~ "OTHER"
))
d <- filter(d , ptype == "CREDIT" | ptype == "CASH")
d <- d[, c(1, 3, 4)]
summary(d)
by_date_type <- group_by(d, date, ptype)
by_date_type$amount <- by_date_type$amount / 1000
by_date_type
g <- ggplot(by_date_type, aes(x = date, y = amount, col = ptype))
g + geom_point() + theme(axis.text.x = element_text(angle = 75, hjust = 1))
g <- g + geom_point() + theme(axis.text.x = element_text(angle = 75, hjust = 1))
g
g + geom_smooth(method = "lm")
?geom_smooth
g + geom_smooth(method = "auto")
g + geom_smooth(method = "lm") + geom_line(
)
credit_p <- filter(by_date_type, ptype == "CREDIT")
credit_p
g1 <- ggplot(credit_p, aes(x = date, y = amount)) + geom_point()
g1
g1 + geom_smooth(method = "lm")
g1 + geom_smooth()
m <- lm(amount ~ ., data = credit_p)
m <- lm(amount ~ date, data = credit_p)
plot(m)
summary(lm)
summary(m)
summary(m)$coef
plot(m$fitted.values, credit_p$amount)
plot(m)
summary(credit_p$amount)
table(credit_p$amount)
summary(credit_p$
)
summary(credit_p$amount)
resid(
)
